name: csv-to-csvw action
description: Generate CSV-W from csv upload to repository.
author: Connected Open Government Statistics (COGS)

branding:
  icon: box
  color: white

on:
  push:
    branches:
      - main

runs:
  using: composite
  steps:
    - name: Set up Python 3.9
      uses: actions/setup-python@v2
      with:
        python-version: 3.9

    - name: Install csvcubed
      run: pip install csvcubed
      shell: bash

    - name: Verify csvcubed installation
      run: csvcubed version
      shell: bash

    - name: Check out repository
      uses: actions/checkout@v2
      with:
        fetch-depth: 0

    - name: View working directory
      run: ls -la $GITHUB_WORKSPACE
      shell: bash

    - name: Configure git
      run: |
        git config --global user.name "CSV-W from csv upload generator"
        git pull
      shell: bash

    - name: Get all added/changed/removed files
      id: get-added-changed-removed-files
      uses: jitterbit/get-changed-files@v1
      with:
        format: "csv"

    - name: Build and inspect new files
      id: build-and-inspect-inputs
      run: |
        echo "::set-output name=has_outputs::false"
        added_modified_files=${{steps.get-added-changed-removed-files.outputs.added_modified}}
        echo "added_modified_files: ${added_modified_files[@]}"

        for file in "${added_modified_files[@]}"; do
          echo "${file}"
          file_path="${file%.*}"
          file_name="${file_path##*/}"
          file_extension="${file##*.}"
          out_path="out/${file_path}/"
          
          # Detects the top folder from the file path. E.g. out/ is the top folder when the path is out/sub-folder/my-data.csv
          top_folder=$(echo "$file_path" | cut -d "/" -f1)

          echo "file_path: ${file_path}"
          echo "file_name: ${file_name}"
          echo "file_extension: ${file_extension}"
          echo "out_path: ${out_path}"
          echo "top_folder: ${top_folder}"

          # The out/ folder is used for storing the outputs generated by csvcubed build and inspect commands. Hence, the user should not use this folder to commit any inputs. Any inputs committed to this folder will not be procssed.
          if [[ ($file_extension == "csv" || $file_extension == "json") && $top_folder != "out" ]]; then
            echo $'\n'
            echo "Processing file ${file}"
            echo "Output path is ${out_path}"

            csv_file=""
            config_file=""
            if [[ $file_extension == "csv" ]]; then
              csv_file=${file}
              for file_secondary in "${added_modified_files[@]}"; do
                file_secondary_name="${file_secondary%.*}"
                file_secondary_extension="${file_secondary##*.}"
                if [[ "${file_secondary_name}.${file_secondary_extension}" == "${file_path}.json" ]]; then
                  config_file="${file_secondary_name}.json"
                fi
              done
            elif [[ $file_extension == "json" ]]; then
              config_file=${file}
              if [[ -f "${file_path}/${file_name}.csv" ]]; then
                csv_file="${file_path}/${file_name}.csv"
              else
                config_file=NULL
              fi
            fi
            
            echo "csv_file for processing: ${csv_file}"
            
            if [[ -f $csv_file ]]; then
              if [[ -f $config_file ]]; then
                echo "Config for ${csv_file} is available: ${config_file}"
                echo "Building CSV-W"
                csvcubed build $csv_file -c $config_file --out $out_path --validation-errors-to-file
              else
                echo "Config for ${csv_file} is not available"
                echo "Building CSV-W"
                csvcubed build $csv_file --out $out_path --validation-errors-to-file
              fi
              
              echo "Inspecting CSV-W"
              mapfile -d $'\0' inspectable_files < <(find "${GITHUB_WORKSPACE}/${out_path}" -name "*.csv-metadata.json" -type f -print0)
            
              for file in "${inspectable_files[@]}"; do
                echo "Inspecting file ${file}"
                file_path="${file%.*}"
                file_name="${file_path##*/}"
                inspect_output_file="${out_path}${file_name}_inspect_output.txt"

                csvcubed inspect $file > $inspect_output_file
              done
              echo "::set-output name=has_outputs::true"
            fi
          fi
        done
      shell: bash

    - name: Process all deleted files
      id: process-deleted-files
      run: |
        ls
        deleted_files=$steps.get-added-changed-removed-files.outputs.removed
        bash scripts/handle_deleted_files.sh $deleted_files
      shell: bash

    - name: Commit generated CSV-Ws and logs to the repository
      #if: $steps.build-and-inspect-inputs.outputs.has_outputs == true
      run: |
        echo $'\nCommitting CSV-Ws\n'
        git add out/
        git commit -m "CSV-Ws generated from csv upload - $(date +'%d-%m-%Y at %H:%M:%S')"
        git push
      shell: bash

    - name: Publish CSV-Ws and logs to artefacts
      #if: $steps.build-and-inspect-inputs.outputs.has_outputs == true
      uses: actions/upload-artifact@v2
      with:
        name: assets-for-download
        path: out

    - name: Publish CSV-Ws and logs to GitHub Pages
      #if: $steps.build-and-inspect-inputs.outputs.has_outputs == true
      run: |
        echo "Publishing to GitHub Pages"
        git checkout -b gh-pages
        rm -r LICENSE
        rm -r README.md

        repo_name=${GITHUB_REPOSITORY#*/}    
        username=${GITHUB_REPOSITORY_OWNER}
        commit_id=${GITHUB_SHA}      
        mapfile -d ',' -t out_files < <(printf '%s,' $(find . -type f -path '*out/*'))
        processed_out_files=$(printf ",%s" "${out_files[@]}")

        bash scripts/generate_git_pages_html.sh $repo_name $username $commit_id $processed_out_files

        git add .nojekyll
        git add index.html
        git commit -a -m "Updating outputs in GitHub Pages - $(date +'%d-%m-%Y at %H:%M:%S')"
        git push --set-upstream origin gh-pages -f
      shell: bash
